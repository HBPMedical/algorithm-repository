[![CHUV](https://img.shields.io/badge/CHUV-LREN-AF4C64.svg)](https://www.unil.ch/lren/en/home.html) [![JSI](https://img.shields.io/badge/JSI-KT-AF4C64.svg)](http://kt.ijs.si/) [![TAU](https://img.shields.io/badge/TAU-ICTAF-AD2C32.svg)](http://ictaf.tau.ac.il/index.asp?lang=eng) [![Codacy Badge](https://api.codacy.com/project/badge/Grade/a170b1b08f81441f85c004480ddaac0f)](https://www.codacy.com/app/hbp-mip/algorithm-repository?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=HBPMedical/algorithm-repository&amp;utm_campaign=Badge_Grade) [![CircleCI](https://circleci.com/gh/HBPMedical/algorithm-repository.svg?style=svg)](https://circleci.com/gh/HBPMedical/algorithm-repository)

# Algorithm repository

This is the repository of algorithms for the [MIP](https://mip.humanbrainproject.eu).

Algorithms, written in their native language (R, Matlab, Python, Java...) are encapsulated in a Docker container that provides them with the runtime environment necessary to execute this function.

The environment variables provided to the Docker container are used as parameters to the function or algorithm to execute.

Currently, we expect the Docker containers to be autonomous:

* they should connect to a database and retrieve the dataset to process
* they should process the data, taking into account the parameters given as environment variables to the Docker container
* they should store the results into the results database.

The format of the results should be easily shared.

* For algorithms providing statistical analysis or machine learning, we require the results to be in [PFA format](http://dmg.org/pfa/) in its YAML or JSON form.
* For algorithms providing visualisations, we support different formats, including Highcharts, Vis.js, PNG and SVG.
* For algorithms providing tabular data, we expect a JSON output in this format: [Tabular Data Resource](https://github.com/frictionlessdata/specs/blob/master/specs/tabular-data-resource.md)

# List of algorithms

## [hbpmip/python-anova](./python-anova/): Anova algorithm
[![DockerHub](https://img.shields.io/badge/docker-hbpmip%2Fpython--anova-008bb8.svg)](https://hub.docker.com/r/hbpmip/python-anova/) [![ImageVersion](https://images.microbadger.com/badges/version/hbpmip/python-anova.svg)](https://hub.docker.com/r/hbpmip/python-anova/tags "hbpmip/python-anova image tags") [![ImageLayers](https://images.microbadger.com/badges/image/hbpmip/python-anova.svg)](https://microbadger.com/#/images/hbpmip/python-anova "hbpmip/python-anova on microbadger")

This is a Python implementation of Anova.

## [hbpmip/python-correlation-heatmap](./python-correlation-heatmap/): Correlation heatmap
[![DockerHub](https://img.shields.io/badge/docker-hbpmip%2Fpython--correlation--heatmap-008bb8.svg)](https://hub.docker.com/r/hbpmip/python-correlation-heatmap/) [![ImageVersion](https://images.microbadger.com/badges/version/hbpmip/python-correlation-heatmap.svg)](https://hub.docker.com/r/hbpmip/python-correlation-heatmap/tags "hbpmip/python-correlation-heatmap image tags") [![ImageLayers](https://images.microbadger.com/badges/image/hbpmip/python-correlation-heatmap.svg)](https://microbadger.com/#/images/hbpmip/python-correlation-heatmap "hbpmip/python-correlation-heatmap on microbadger")

Calculate correlation heatmap, only works for real variables.
Run it on single node or in a distributed mode.
First, intermediate mode calculates covariance matrix from a single node, then aggregate mode is used after intermediate to combine statistics from multiple jobs and produce the final graph.

## [hbpmip/python-distributed-pca](./python-correlation-heatmap/): PCA - principal components analysis
[![DockerHub](https://img.shields.io/badge/docker-hbpmip%2Fpython--distributed--pca-008bb8.svg)](https://hub.docker.com/r/hbpmip/python-distributed-pca/) [![ImageVersion](https://images.microbadger.com/badges/version/hbpmip/python-distributed-pca.svg)](https://hub.docker.com/r/hbpmip/python-distributed-pca/tags "hbpmip/python-distributed-pca image tags") [![ImageLayers](https://images.microbadger.com/badges/image/hbpmip/python-distributed-pca.svg)](https://microbadger.com/#/images/hbpmip/python-distributed-pca "hbpmip/python-distributed-pca on microbadger")

Calculate PCA, only works for real variables.
Run it on single node or in a distributed mode.
First, intermediate mode calculates covariance matrix from a single node, then aggregate mode is used after intermediate to combine statistics from multiple jobs and produce the final graph.

Code is shared with [hbpmip/python-correlation-heatmap](./python-correlation-heatmap/)

python-distributed-kmeans
Implementation of distributed k-means clustering (https://github.com/MRN-Code/dkmeans) in Python. It uses Single-Shot Decentralized LLoyd (https://github.com/MRN-Code/dkmeans#single-shot-decentralized-lloyd).

Intermediate mode calculates clusters on a single node, while aggregate mode is merging the clusters according to least merging error (e.g. smallest distance between centroids).

python-histograms
Calculates histogram of nominal or real variable grouped by nominal variables in independent variables. Histogram edges are taken from `minValue` and `maxValue` property of dependent variable. If not avaiable, then these values are calculated dynamically from dependent values (this won't work in distributed mode though).

python-jsi-hedwig
Hedwig method for semantic subgroup discovery.  (https://github.com/anzev/hedwig).

python-jsi-hinmine
The HINMINE algorithm for network-based propositionalization is an algorithm for data analysis based on network analysis methods.

The input for the algorithm is a data set containing instances with real-valued features. The purpose of the algorithm is to construct a new set of features for further analysis by other data mining algorithms. The algorithm outputs a data set with features, generated for each data instance in the input data set. The features represent how close a given instance is to the other instances in the data set. The closeness of instances is measured using the PageRank algorithm, calculated on a network constructed from instance similarities.
python-knn
Implementation of k-nearest neighbors algorithm (https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) in Python.

Run it on single node or in a distributed mode.

python-linear-regression
Python implementation of multivariate linear regression. It supports both continuous and categorical as independent variables. Run it on single node or in a distributed mode.
Python implementation of logistic regressions on one class versus the others. Only single-node mode is supported

python-sgd-regression
This is a Python implementation of scikit-learn estimators (http://scikit-learn.org/stable/modules/scaling_strategies.html) that use `partial_fit` method for distributed learning.

Implemented methods:
`linear_model` - calls `SGDRegressor` or `SGDClassifier`
`neural_network` - calls `MLPRegressor` or `MLPClassifier`
`naive_bayes` - calls `MixedNB` (mix of `GaussianNB` and `MultinomialNB`), only works for classification tasks
`gradient_boosting` - calls `GradientBoostingRegressor` or `GradientBoostingClassifier`, does not support distributed training.

python-summary-statistics
It calculates various summary statistics for entire dataset and also for all subgroups created by combining all possible values of nominal covariates. Run it on single node or in a distributed mode.

python-tsne
The python-tsne is a wrapper for the the A-tSNE algorithm developed by N. Pezzotti. The underlying algorithm is an improvement on the Barnes-Hut tSNE (http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf) using an approximated k-nearest neighbor calculation.

# Algorithm capabilities




# Acknowledgements

This work has been funded by the European Union Seventh Framework Program (FP7/2007Â­2013) under grant agreement no. 604102 (HBP)

This work is part of SP8 of the Human Brain Project (SGA1).
